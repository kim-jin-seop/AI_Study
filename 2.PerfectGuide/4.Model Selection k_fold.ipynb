{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "885cb15b",
   "metadata": {},
   "source": [
    "## k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa7018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data sets size :  150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "print('data sets size : ', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f68cb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 교차 검증 정확도 :  1.0\n",
      "1 번째 학습 데이터 크기 :  120\n",
      "1 번째 검증 데이터 크기 :  30\n",
      "1 번째 검증 세트 인덱스 :  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "2 번째 교차 검증 정확도 :  0.9667\n",
      "2 번째 학습 데이터 크기 :  120\n",
      "2 번째 검증 데이터 크기 :  30\n",
      "2 번째 검증 세트 인덱스 :  [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "3 번째 교차 검증 정확도 :  0.8667\n",
      "3 번째 학습 데이터 크기 :  120\n",
      "3 번째 검증 데이터 크기 :  30\n",
      "3 번째 검증 세트 인덱스 :  [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "4 번째 교차 검증 정확도 :  0.9333\n",
      "4 번째 학습 데이터 크기 :  120\n",
      "4 번째 검증 데이터 크기 :  30\n",
      "4 번째 검증 세트 인덱스 :  [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "5 번째 교차 검증 정확도 :  0.7333\n",
      "5 번째 학습 데이터 크기 :  120\n",
      "5 번째 검증 데이터 크기 :  30\n",
      "5 번째 검증 세트 인덱스 :  [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "평균 검증 정확도 :  0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "# kfold.split(features)의 반환값 : 학습에서 사용할 index list, 검증에서 사용할 index list\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    print(n_iter,\"번째 교차 검증 정확도 : \",accuracy)\n",
    "    print(n_iter,\"번째 학습 데이터 크기 : \",train_size)\n",
    "    print(n_iter,\"번째 검증 데이터 크기 : \",test_size)\n",
    "    print(n_iter,\"번째 검증 세트 인덱스 : \", test_index)\n",
    "    print()\n",
    "    \n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print(\"평균 검증 정확도 : \", np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8011b24",
   "metadata": {},
   "source": [
    "## Stratified k-fold\n",
    "\n",
    "- 사용 목적 : 불균형한 데이터를 적절하게 학습하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28444df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71008649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 교차검증\n",
      "학습 데이터 분포 \n",
      " 1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 데이터 분포 \n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "\n",
      "2 교차검증\n",
      "학습 데이터 분포 \n",
      " 0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 데이터 분포 \n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "\n",
      "3 교차검증\n",
      "학습 데이터 분포 \n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 데이터 분포 \n",
      " 2    50\n",
      "Name: label, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#결과값 확인 시 문제점이 있음을 알 수 있음\n",
    "kfold = KFold(n_splits=3)\n",
    "\n",
    "n_iter=0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    \n",
    "    print(n_iter, \"교차검증\")\n",
    "    print(\"학습 데이터 분포 \\n\", label_train.value_counts())\n",
    "    print(\"검증 데이터 분포 \\n\", label_test.value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c72215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 교차 검증 : \n",
      "학습 레이블 데이터 분포 \n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 \n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "2 교차 검증 : \n",
      "학습 레이블 데이터 분포 \n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 \n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "3 교차 검증 : \n",
      "학습 레이블 데이터 분포 \n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 \n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data값과 label값을 모두 넣어주어야 함\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print(n_iter,\"교차 검증 : \")\n",
    "    print(\"학습 레이블 데이터 분포 \\n\", label_train.value_counts())\n",
    "    print(\"검증 레이블 데이터 분포 \\n\", label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3bfaf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 교차검증 정확도 :  0.98  학습데이터 크기 :  100  검증 데이터 크기 :  50\n",
      "검증 데이터 인덱스 :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "2 번째 교차검증 정확도 :  0.94  학습데이터 크기 :  100  검증 데이터 크기 :  50\n",
      "검증 데이터 인덱스 :  [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "3 번째 교차검증 정확도 :  0.98  학습데이터 크기 :  100  검증 데이터 크기 :  50\n",
      "검증 데이터 인덱스 :  [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "교차 검증별 정확도 :  [0.98 0.94 0.98]\n",
      "평균 검증 정확도 :  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "cv_accuracy=[]\n",
    "\n",
    "for train_index, test_index in skfold.split(features,label):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    print(n_iter,\"번째 교차검증 정확도 : \", accuracy, \" 학습데이터 크기 : \",train_size, \" 검증 데이터 크기 : \",test_size)\n",
    "    print(\"검증 데이터 인덱스 : \",test_index)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    print()\n",
    "\n",
    "print(\"교차 검증별 정확도 : \", np.round(cv_accuracy,4))\n",
    "print(\"평균 검증 정확도 : \", np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca543f",
   "metadata": {},
   "source": [
    "## cross_val_score()\n",
    "\n",
    "- straitified kfold 방식으로 학습(회귀는 k-fold로 수행)\n",
    "- 편리하게 검증 가능\n",
    "- 모델,x,y, 성능평가방식, k-fold 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6007e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도:  [0.98 0.94 0.98]\n",
      "평균 검증 정확도:  0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris_data =load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state= 156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy',cv=3)\n",
    "print('교차 검증별 정확도: ',np.round(scores,4))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ece4ebb",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "- 최적의 하이퍼파라미터를 찾기 위해 모든 경우의 수를 학습하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44d8ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \n",
    "                                                    test_size=0.2, random_state=121)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd1c00c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#학습할 파라미터들은 반드시 dictionary로 넣어준다.(value는 무조건 list!)\n",
    "#refit-> 최적의 파라미터를 찾았다면 그 파라미터를 활용하여 학습을 시켜줌(predict 가능)\n",
    "grid_dtree = GridSearchCV(dtree, param_grid= parameters, cv=3, refit=True, return_train_score=True)\n",
    "\n",
    "grid_dtree.fit(X_train,y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score',\n",
    "          'split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "453c70cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00033355, 0.        , 0.00033355, 0.        , 0.00033363,\n",
       "        0.        ]),\n",
       " 'std_fit_time': array([0.00047171, 0.        , 0.00047171, 0.        , 0.00047182,\n",
       "        0.        ]),\n",
       " 'mean_score_time': array([0.00033371, 0.00033347, 0.        , 0.00033363, 0.        ,\n",
       "        0.00066733]),\n",
       " 'std_score_time': array([0.00047193, 0.0004716 , 0.        , 0.00047182, 0.        ,\n",
       "        0.00047188]),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 2, 2, 3, 3],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 3, 2, 3, 2, 3],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 1, 'min_samples_split': 2},\n",
       "  {'max_depth': 1, 'min_samples_split': 3},\n",
       "  {'max_depth': 2, 'min_samples_split': 2},\n",
       "  {'max_depth': 2, 'min_samples_split': 3},\n",
       "  {'max_depth': 3, 'min_samples_split': 2},\n",
       "  {'max_depth': 3, 'min_samples_split': 3}],\n",
       " 'split0_test_score': array([0.7  , 0.7  , 0.925, 0.925, 0.975, 0.975]),\n",
       " 'split1_test_score': array([0.7, 0.7, 1. , 1. , 1. , 1. ]),\n",
       " 'split2_test_score': array([0.7 , 0.7 , 0.95, 0.95, 0.95, 0.95]),\n",
       " 'mean_test_score': array([0.7       , 0.7       , 0.95833333, 0.95833333, 0.975     ,\n",
       "        0.975     ]),\n",
       " 'std_test_score': array([1.11022302e-16, 1.11022302e-16, 3.11804782e-02, 3.11804782e-02,\n",
       "        2.04124145e-02, 2.04124145e-02]),\n",
       " 'rank_test_score': array([5, 5, 3, 3, 1, 1]),\n",
       " 'split0_train_score': array([0.7   , 0.7   , 0.975 , 0.975 , 0.9875, 0.9875]),\n",
       " 'split1_train_score': array([0.7   , 0.7   , 0.9375, 0.9375, 0.9625, 0.9625]),\n",
       " 'split2_train_score': array([0.7   , 0.7   , 0.9625, 0.9625, 0.9875, 0.9875]),\n",
       " 'mean_train_score': array([0.7       , 0.7       , 0.95833333, 0.95833333, 0.97916667,\n",
       "        0.97916667]),\n",
       " 'std_train_score': array([1.11022302e-16, 1.11022302e-16, 1.55902391e-02, 1.55902391e-02,\n",
       "        1.17851130e-02, 1.17851130e-02])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtree.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd169436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터:  {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.9750\n",
      "테스트 데이터 세트 정확도 :  0.9667\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터: ',grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))\n",
    "\n",
    "pred = grid_dtree.predict(X_test)\n",
    "print(\"테스트 데이터 세트 정확도 : {0: .4f}\".format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d25fdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "pred = estimator.predict(X_test)\n",
    "print(\"테스트 데이터 세트 정확도: {0:.4f}\".format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c215bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
